{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f04077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 250}\n",
      "Best CV MSE: 13.086534212895705\n",
      "Validation MSE: 12.880139844022148\n",
      "       id  Pred_Calories\n",
      "0  750000      27.780828\n",
      "1  750001     107.989243\n",
      "2  750002      86.624619\n",
      "3  750003     124.263741\n",
      "4  750004      75.725960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# 1) Carica i dati\n",
    "train_path = r'C:\\Users\\fabri\\Desktop\\MarcoPatierno_DepositoCorsoPython\\env\\Giorno 22 06-05\\kaggle_competition\\data\\train.csv'\n",
    "test_path  = r'C:\\Users\\fabri\\Desktop\\MarcoPatierno_DepositoCorsoPython\\env\\Giorno 22 06-05\\kaggle_competition\\data\\test.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "# 2) Funzione di feature engineering (NO target leakage: non uso mai df['Calories'])\n",
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "    # codifica Sex\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    # BMI e Body Surface Area\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "    df['BSA'] = 0.007184 * df['Weight'] ** 0.425 * df['Height'] ** 0.725\n",
    "    # Delta temperatura\n",
    "    df['Delta_Temp'] = df['Body_Temp'] - 37.0\n",
    "    # HR per kg\n",
    "    df['HR_per_kg'] = df['Heart_Rate'] / df['Weight']\n",
    "    # battiti totali e durate\n",
    "    df['Heart_Beats_Total'] = df['Heart_Rate'] * df['Duration']\n",
    "    # trasformazioni su Duration\n",
    "    df['log_Duration']  = np.log1p(df['Duration'])\n",
    "    df['sqrt_Duration'] = np.sqrt(df['Duration'])\n",
    "    # BMR (Harris-Benedict)\n",
    "    df['BMR'] = np.where(\n",
    "        df['Sex'] == 0,\n",
    "        88.362 + 13.397 * df['Weight'] + 4.799 * df['Height'] - 5.677 * df['Age'],\n",
    "        447.593 +  9.247 * df['Weight'] + 3.098 * df['Height'] - 4.330 * df['Age']\n",
    "    )\n",
    "    # MaxHR e percentuale\n",
    "    df['MaxHR']     = 220 - df['Age']\n",
    "    df['pct_MaxHR'] = df['Heart_Rate'] / df['MaxHR']\n",
    "    # HR * Duration^2\n",
    "    df['HR_Dur2'] = df['Heart_Rate'] * (df['Duration'] ** 2)\n",
    "    return df\n",
    "\n",
    "# 3) Applica la stessa funzione a train e test\n",
    "train_fe = make_features(df_train)\n",
    "test_fe  = make_features(df_test)\n",
    "\n",
    "# 4) Prepara X e y\n",
    "X = train_fe.drop(columns=['id', 'Calories'])\n",
    "y = train_fe['Calories']\n",
    "\n",
    "# 5) Split train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 6) Grid search su XGBoost\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators':    [100, 200, 250],\n",
    "    'max_depth':       [3, 5, 7],\n",
    "    'learning_rate':   [0.01, 0.05, 0.1]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    xgb, param_grid, cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV MSE:\", -grid.best_score_)\n",
    "\n",
    "# 7) Valutazione su validation set\n",
    "y_val_pred = grid.predict(X_val)\n",
    "val_mse = ((y_val - y_val_pred) ** 2).mean()\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "\n",
    "# 8) Predizione su test set\n",
    "#   - prima allineo nomi e ordine delle colonne a quelli di X_train\n",
    "X_test = test_fe.drop(columns=['id'])\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "df_test['Pred_Calories'] = grid.predict(X_test)\n",
    "print(df_test[['id', 'Pred_Calories']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35fc1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 3.5889\n"
     ]
    }
   ],
   "source": [
    "val_rmse = np.sqrt(val_mse)\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05046f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 250}\n",
      "CV MSE: 13.0865   CV RMSE: 3.6175\n",
      "Validation MSE: 12.8801   Validation RMSE: 3.5889\n",
      "       id  Pred_Calories\n",
      "0  750000      27.780828\n",
      "1  750001     107.989243\n",
      "2  750002      86.624619\n",
      "3  750003     124.263741\n",
      "4  750004      75.725960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) Carica i dati\n",
    "train_path = r'C:\\Users\\fabri\\Desktop\\MarcoPatierno_DepositoCorsoPython\\env\\Giorno 22 06-05\\kaggle_competition\\data\\train.csv'\n",
    "test_path  = r'C:\\Users\\fabri\\Desktop\\MarcoPatierno_DepositoCorsoPython\\env\\Giorno 22 06-05\\kaggle_competition\\data\\test.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "# 2) Funzione di feature engineering (no target leakage)\n",
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "    df['BSA'] = 0.007184 * df['Weight']**0.425 * df['Height']**0.725\n",
    "    df['Delta_Temp'] = df['Body_Temp'] - 37.0\n",
    "    df['HR_per_kg'] = df['Heart_Rate'] / df['Weight']\n",
    "    df['Heart_Beats_Total'] = df['Heart_Rate'] * df['Duration']\n",
    "    df['log_Duration']  = np.log1p(df['Duration'])\n",
    "    df['sqrt_Duration'] = np.sqrt(df['Duration'])\n",
    "    df['BMR'] = np.where(\n",
    "        df['Sex'] == 0,\n",
    "        88.362 + 13.397 * df['Weight'] + 4.799 * df['Height'] - 5.677 * df['Age'],\n",
    "        447.593 +  9.247 * df['Weight'] + 3.098 * df['Height'] - 4.330 * df['Age']\n",
    "    )\n",
    "    df['MaxHR']     = 220 - df['Age']\n",
    "    df['pct_MaxHR'] = df['Heart_Rate'] / df['MaxHR']\n",
    "    df['HR_Dur2']   = df['Heart_Rate'] * (df['Duration'] ** 2)\n",
    "    return df\n",
    "\n",
    "# 3) Applica feature engineering a train e test\n",
    "train_fe = make_features(df_train)\n",
    "test_fe  = make_features(df_test)\n",
    "\n",
    "# 4) Prepara X_raw e X_test_raw (senza id e target)\n",
    "X_raw       = train_fe.drop(columns=['id', 'Calories'])\n",
    "X_test_raw  = test_fe.drop(columns=['id'])\n",
    "\n",
    "# 5) Trasformazione logaritmica su tutte le feature\n",
    "#    - per ciascuna colonna, se min <= 0, shift = (-min + 1), altrimenti shift = 0\n",
    "X     = X_raw.copy()\n",
    "X_test = X_test_raw.copy()\n",
    "for col in X.columns:\n",
    "    min_val = min(X[col].min(), X_test[col].min())\n",
    "    shift   = -min_val + 1 if min_val <= 0 else 0\n",
    "    X[col]      = np.log1p(X[col] + shift)\n",
    "    X_test[col] = np.log1p(X_test[col] + shift)\n",
    "\n",
    "# 6) Split train/validation\n",
    "y = train_fe['Calories']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 7) Grid search su XGBoost\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators':  [100, 200, 250],\n",
    "    'max_depth':     [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    xgb, param_grid, cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 8) Calcolo di CV RMSE e validation RMSE\n",
    "best_mse_cv = -grid.best_score_\n",
    "best_rmse_cv = np.sqrt(best_mse_cv)\n",
    "y_val_pred  = grid.predict(X_val)\n",
    "val_mse     = mean_squared_error(y_val, y_val_pred)\n",
    "val_rmse    = np.sqrt(val_mse)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(f\"CV MSE: {best_mse_cv:.4f}   CV RMSE: {best_rmse_cv:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse:.4f}   Validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "# 9) Predizione sul test set\n",
    "df_test['Pred_Calories'] = grid.predict(X_test)\n",
    "print(df_test[['id', 'Pred_Calories']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace1821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSLE: 0.0614\n"
     ]
    }
   ],
   "source": [
    "# Calcolo della Root Mean Squared Logarithmic Error (RMSLE) sulla validation set\n",
    "rmsle = np.sqrt(np.mean((np.log1p(y_val_pred) - np.log1p(y_val)) ** 2))\n",
    "print(f\"Validation RMSLE: {rmsle:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0e7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model Validation MSE: 13.1928, RMSE: 3.6322\n",
      "Custom model Validation RMSLE: 0.0607\n",
      "       id  Pred_Calories_custom\n",
      "0  750000             27.780058\n",
      "1  750001            107.488564\n",
      "2  750002             87.484024\n",
      "3  750003            125.975304\n",
      "4  750004             75.889946\n"
     ]
    }
   ],
   "source": [
    "# Fit XGBoost with specified hyperparameters\n",
    "xgb_custom = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_custom.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation on validation set\n",
    "y_val_pred_custom = xgb_custom.predict(X_val)\n",
    "mse_custom = mean_squared_error(y_val, y_val_pred_custom)\n",
    "rmse_custom = np.sqrt(mse_custom)\n",
    "print(f\"Custom model Validation MSE: {mse_custom:.4f}, RMSE: {rmse_custom:.4f}\")\n",
    "rmsle_custom = np.sqrt(np.mean((np.log1p(y_val_pred_custom) - np.log1p(y_val)) ** 2))\n",
    "print(f\"Custom model Validation RMSLE: {rmsle_custom:.4f}\")\n",
    "# Predict on test set\n",
    "df_test['Pred_Calories_custom'] = xgb_custom.predict(X_test)\n",
    "print(df_test[['id', 'Pred_Calories_custom']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# 1) Carica i dati\n",
    "train_path = r'C:\\Users\\fabri\\Desktop\\MarcoPatierno_DepositoCorsoPython\\env\\Giorno 22 06-05\\kaggle_competition\\data\\train.csv'\n",
    "test_path  = r'C:\\Users\\fabri\\Desktop\\MarcoPatierno_DepositoCorsoPython\\env\\Giorno 22 06-05\\kaggle_competition\\data\\test.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "# 2) Funzione di feature engineering (senza target leakage)\n",
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "    df['BSA'] = 0.007184 * df['Weight']**0.425 * df['Height']**0.725\n",
    "    df['Delta_Temp'] = df['Body_Temp'] - 37.0\n",
    "    df['HR_per_kg'] = df['Heart_Rate'] / df['Weight']\n",
    "    df['Heart_Beats_Total'] = df['Heart_Rate'] * df['Duration']\n",
    "    df['log_Duration']  = np.log1p(df['Duration'])\n",
    "    df['sqrt_Duration'] = np.sqrt(df['Duration'])\n",
    "    df['BMR'] = np.where(\n",
    "        df['Sex'] == 0,\n",
    "        88.362 + 13.397 * df['Weight'] + 4.799 * df['Height'] - 5.677 * df['Age'],\n",
    "        447.593 +  9.247 * df['Weight'] + 3.098 * df['Height'] - 4.330 * df['Age']\n",
    "    )\n",
    "    df['MaxHR']     = 220 - df['Age']\n",
    "    df['pct_MaxHR'] = df['Heart_Rate'] / df['MaxHR']\n",
    "    df['HR_Dur2']   = df['Heart_Rate'] * (df['Duration'] ** 2)\n",
    "    return df\n",
    "\n",
    "# 3) Applica feature engineering\n",
    "train_fe = make_features(df_train)\n",
    "test_fe  = make_features(df_test)\n",
    "\n",
    "# 4) Prepara X_raw, y_orig e X_test_raw\n",
    "X_raw      = train_fe.drop(columns=['id', 'Calories'])\n",
    "y_orig     = train_fe['Calories']\n",
    "X_test_raw = test_fe.drop(columns=['id'])\n",
    "\n",
    "# 5) Log‐trasformazione automatica di tutte le feature\n",
    "X      = X_raw.copy()\n",
    "X_test = X_test_raw.copy()\n",
    "for col in X.columns:\n",
    "    min_val = min(X[col].min(), X_test[col].min())\n",
    "    shift   = -min_val + 1 if min_val <= 0 else 0\n",
    "    X[col]      = np.log1p(X[col] + shift)\n",
    "    X_test[col] = np.log1p(X_test[col] + shift)\n",
    "\n",
    "# 6) Split train/validation (mantenendo target originale per metriche)\n",
    "X_train, X_val, y_train_orig, y_val_orig = train_test_split(\n",
    "    X, y_orig, test_size=0.2, random_state=42\n",
    ")\n",
    "# Trasforma il target in log1p per ottimizzare RMSLE\n",
    "y_train = np.log1p(y_train_orig)\n",
    "y_val   = np.log1p(y_val_orig)\n",
    "\n",
    "# 7) Spazio di ricerca iperparametri\n",
    "param_dist = {\n",
    "    'learning_rate':    [0.01, 0.05, 0.1],\n",
    "    'max_depth':        [5, 7, 10, 12],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma':            [0, 0.1, 0.2, 0.5],\n",
    "    'subsample':        [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha':        [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda':       [1, 2, 5],\n",
    "    'booster':          ['gbtree', 'dart']\n",
    "}\n",
    "\n",
    "# 8) RandomizedSearchCV con early stopping\n",
    "xgb = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_estimators=1000,\n",
    "    verbosity=0\n",
    ")\n",
    "search = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "search.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best = search.best_estimator_\n",
    "\n",
    "# 9) Valuta su CV e validation set\n",
    "cv_rmsle  = np.sqrt(-search.best_score_)\n",
    "y_val_log = best.predict(X_val)\n",
    "y_val_pred = np.expm1(y_val_log)\n",
    "val_rmse   = np.sqrt(mean_squared_error(y_val_orig, y_val_pred))\n",
    "val_rmsle  = np.sqrt(mean_squared_log_error(y_val_orig, y_val_pred))\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(f\"CV RMSLE: {cv_rmsle:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}, RMSLE: {val_rmsle:.4f}\")\n",
    "\n",
    "# 10) Predizioni finali sul test set (invertendo il log)\n",
    "df_test['Pred_Calories'] = np.expm1(best.predict(X_test))\n",
    "print(df_test[['id', 'Pred_Calories']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25d9e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nessuna variabile da eliminare. Selezione completata.\n",
      "\n",
      "Feature finali selezionate:\n",
      "['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'BSA', 'Delta_Temp', 'HR_per_kg', 'Heart_Beats_Total', 'log_Duration', 'sqrt_Duration', 'BMR', 'MaxHR', 'pct_MaxHR', 'HR_Dur2']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def elimina_variabili_vif_pvalue(X_train, y_train, vif_threshold=10.0, pvalue_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Rimuove variabili da X_train basandosi su VIF e p-value.\n",
    "    \n",
    "    - Elimina solo variabili con VIF > soglia e p-value > soglia.\n",
    "    - Ricalcola VIF e p-value dopo ogni eliminazione.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copia dei dati per lavorare in sicurezza\n",
    "    X_current = X_train.copy()\n",
    "    \n",
    "    # Aggiungi costante per statsmodels\n",
    "    X_const = sm.add_constant(X_current)\n",
    "    \n",
    "    while True:\n",
    "        # Modello OLS per calcolare p-value\n",
    "        model = sm.OLS(y_train, X_const).fit()\n",
    "        pvalues = model.pvalues.drop('const')  # escludi l'intercetta\n",
    "        \n",
    "        # Calcolo VIF\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"Feature\"] = X_current.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X_current.values, i) for i in range(X_current.shape[1])]\n",
    "        \n",
    "        # Unisco p-value e VIF\n",
    "        stats = vif.copy()\n",
    "        stats[\"p-value\"] = pvalues.values\n",
    "        \n",
    "        # Trova candidati da eliminare: VIF alto + p-value alto\n",
    "        candidates = stats[(stats[\"VIF\"] > vif_threshold) & (stats[\"p-value\"] > pvalue_threshold)]\n",
    "        \n",
    "        if candidates.empty:\n",
    "            print(\"\\nNessuna variabile da eliminare. Selezione completata.\")\n",
    "            break\n",
    "        \n",
    "        # Elimina la variabile con il VIF più alto tra i candidati\n",
    "        worst_feature = candidates.sort_values(by=\"VIF\", ascending=False)[\"Feature\"].iloc[0]\n",
    "        print(f\"Rimuovo '{worst_feature}' con VIF = {candidates.loc[candidates['Feature'] == worst_feature, 'VIF'].values[0]:.2f} \"\n",
    "              f\"e p-value = {candidates.loc[candidates['Feature'] == worst_feature, 'p-value'].values[0]:.4f}\")\n",
    "        \n",
    "        # Aggiorna i dati\n",
    "        X_current = X_current.drop(columns=[worst_feature])\n",
    "        X_const = sm.add_constant(X_current)\n",
    "    \n",
    "    print(\"\\nFeature finali selezionate:\")\n",
    "    print(X_current.columns.tolist())\n",
    "    \n",
    "    return X_current\n",
    "\n",
    "X_current = elimina_variabili_vif_pvalue(X_train, y_train, vif_threshold=10.0, pvalue_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbb667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Q1         Q3       IQR     lower      upper\n",
      "Sex                0.693147   1.098612  0.405465  0.084950   1.706810\n",
      "Age                3.367296   3.970292  0.602996  2.462802   4.874786\n",
      "Height             5.105945   5.225747  0.119801  4.926244   5.405448\n",
      "Weight             4.158883   4.477337  0.318454  3.681202   4.955017\n",
      "Duration           2.197225   3.178054  0.980829  0.725981   4.649298\n",
      "Heart_Rate         4.488636   4.644391  0.155755  4.255005   4.878023\n",
      "Body_Temp          3.703768   3.730501  0.026733  3.663668   3.770601\n",
      "BMI                3.188624   3.276570  0.087946  3.056704   3.408489\n",
      "BSA                0.988039   1.132696  0.144657  0.771054   1.349681\n",
      "Delta_Temp         1.280934   1.547563  0.266629  0.880991   1.947506\n",
      "HR_per_kg          0.739428   0.919793  0.180365  0.468880   1.190342\n",
      "Heart_Beats_Total  6.591674   7.751045  1.159371  4.852617   9.490102\n",
      "log_Duration       1.162283   1.429846  0.267562  0.760939   1.831189\n",
      "sqrt_Duration      1.342454   1.757139  0.414685  0.720427   2.379166\n",
      "BMR                7.221463   7.549264  0.327801  6.729762   8.040965\n",
      "MaxHR              5.129899   5.262690  0.132791  4.930712   5.461877\n",
      "pct_MaxHR          0.396969   0.459232  0.062263  0.303575   0.552626\n",
      "HR_Dur2            8.669914  10.876178  2.206263  5.360519  14.185572\n",
      "Record prima del filtro: 600000\n",
      "Record dopo filtro IQR:  559239\n"
     ]
    }
   ],
   "source": [
    "# Calcolo dei limiti IQR su X_train\n",
    "Q1 = X_train.quantile(0.25)\n",
    "Q3 = X_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_limit = Q1 - 1.5 * IQR\n",
    "upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "# Tabella dei limiti\n",
    "iqr_limits = pd.DataFrame({\n",
    "    'Q1': Q1,\n",
    "    'Q3': Q3,\n",
    "    'IQR': IQR,\n",
    "    'lower': lower_limit,\n",
    "    'upper': upper_limit\n",
    "})\n",
    "print(iqr_limits)\n",
    "\n",
    "# Rimuovo gli outlier da X_train e y_train\n",
    "mask = ~((X_train < lower_limit) | (X_train > upper_limit)).any(axis=1)\n",
    "X_train_iqr = X_train[mask]\n",
    "y_train_iqr = y_train.loc[mask]\n",
    "\n",
    "print(f\"Record prima del filtro: {X_train.shape[0]}\")\n",
    "print(f\"Record dopo filtro IQR:  {X_train_iqr.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90783661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR model Validation MSE: 14.1958, RMSE: 3.7677\n",
      "IQR model Validation RMSLE: 0.1390\n",
      "       id  Pred_Calories_iqr\n",
      "0  750000          27.572760\n",
      "1  750001         108.658775\n",
      "2  750002          86.211700\n",
      "3  750003         124.607124\n",
      "4  750004          76.455338\n"
     ]
    }
   ],
   "source": [
    "# Fit XGBoost on IQR‐filtered training data using the best params\n",
    "xgb_iqr = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    **grid.best_params_\n",
    ")\n",
    "xgb_iqr.fit(X_train_iqr, y_train_iqr)\n",
    "\n",
    "# Valutazione sul validation set\n",
    "y_val_pred_iqr = xgb_iqr.predict(X_val[X_train_iqr.columns])\n",
    "mse_iqr = mean_squared_error(y_val, y_val_pred_iqr)\n",
    "rmse_iqr = np.sqrt(mse_iqr)\n",
    "print(f\"IQR model Validation MSE: {mse_iqr:.4f}, RMSE: {rmse_iqr:.4f}\")\n",
    "rmsle_iqr = np.sqrt(np.mean((np.log1p(y_val_pred_iqr) - np.log1p(y_val)) ** 2))\n",
    "print(f\"IQR model Validation RMSLE: {rmsle_iqr:.4f}\")\n",
    "# Predizione su test set\n",
    "df_test['Pred_Calories_iqr'] = xgb_iqr.predict(X_test[X_train_iqr.columns])\n",
    "print(df_test[['id', 'Pred_Calories_iqr']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6975a589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation RMSLE: 0.0625\n",
      "       id  Pred_Calories_rf\n",
      "0  750000            27.550\n",
      "1  750001           108.520\n",
      "2  750002            88.350\n",
      "3  750003           124.850\n",
      "4  750004            75.548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1) Fit Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on validation and compute RMSLE\n",
    "y_val_pred_rf = rf.predict(X_val)\n",
    "rmsle_rf = np.sqrt(np.mean((np.log1p(y_val_pred_rf) - np.log1p(y_val)) ** 2))\n",
    "print(f\"Random Forest Validation RMSLE: {rmsle_rf:.4f}\")\n",
    "\n",
    "# 3) Predict on test set and store in df_test\n",
    "df_test['Pred_Calories_rf'] = rf.predict(X_test)\n",
    "print(df_test[['id', 'Pred_Calories_rf']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8d8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
